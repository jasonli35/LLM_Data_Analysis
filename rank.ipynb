{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('data_4072.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['eval_name', 'Precision', 'Type', 'T', 'Weight type', 'Architecture',\n",
       "       'Model', 'fullname', 'Model sha', 'Average ‚¨ÜÔ∏è', 'Hub License', 'Hub ‚ù§Ô∏è',\n",
       "       '#Params (B)', 'Available on the hub', 'MoE', 'Flagged',\n",
       "       'Chat Template', 'CO‚ÇÇ cost (kg)', 'IFEval Raw', 'IFEval', 'BBH Raw',\n",
       "       'BBH', 'MATH Lvl 5 Raw', 'MATH Lvl 5', 'GPQA Raw', 'GPQA', 'MUSR Raw',\n",
       "       'MUSR', 'MMLU-PRO Raw', 'MMLU-PRO', 'Merged', 'Official Providers',\n",
       "       'Upload To Hub Date', 'Submission Date', 'Generation', 'Base Model'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "        ...  \n",
       "4067    False\n",
       "4068    False\n",
       "4069     True\n",
       "4070     True\n",
       "4071     True\n",
       "Name: Available on the hub, Length: 4072, dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Available on the hub']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['üí¨', 'üü¢', 'üî∂', 'ü§ù', 'üü©', 'üå∏', '‚ùì'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"T\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['üí¨ chat models (RLHF, DPO, IFT, ...)', 'üü¢ pretrained',\n",
       "       'üî∂ fine-tuned on domain-specific datasets',\n",
       "       'ü§ù base merges and moerges', 'üü© continuously pretrained',\n",
       "       'üå∏ multimodal', '‚ùì other'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in df[\"Hub License\"] if it is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_rank(num_criteria = [], confident=0.5, num_top_model=5, str_criteria = [], range_matrices = {},rank_reversed = False):\n",
    "    \"\"\"\n",
    "    The function will rank the models based on selected criteria. If the criteria is empty, we will take the average of all the metrics.\n",
    "    @param criteria: The metrics that is most important for this specific tasks. If it is None, we will take the average of these matrics.\n",
    "    @param confident: how much confident user think num_criteria and str_criteria are correct in range of 0-1.\n",
    "    @param num_top_model: The number of top models we want to show.\n",
    "    @param str_criteria: The criteria \n",
    "    @param range_matrices: The range of the criteria that we want to consider, where the key are matrices and \n",
    "    @param rank_reversed: If True, the rank will be reversed.\n",
    "\n",
    "    @return: The rank of the models.\n",
    "    \"\"\"\n",
    "    assert type(num_criteria) == list, \"criteria should be a list\"\n",
    "    # matrices = [\"MMLU-PRO\", \"MUSR\", \"GPQA\", \"MATH Lvl 5\", \"BBH\", \"IFEval\", \"CO‚ÇÇ cost (kg)\", \"Flagged\", \"MoE\", \"#Params (B)\", \"Hub ‚ù§Ô∏è\"]\n",
    "    matrices = [\"MMLU-PRO\", \"MUSR\", \"GPQA\", \"MATH Lvl 5\", \"BBH\", \"IFEval\", \"CO‚ÇÇ cost (kg)\", \"Flagged\", \"MoE\", \"#Params (B)\", \"Hub ‚ù§Ô∏è\"]\n",
    "    for c in num_criteria:\n",
    "        assert c in matrices, f\"criteria {c} is not allowed. Note that it can only take one of the following values: ['MMLU-PRO', 'MUSR', 'GPQA', 'MATH Lvl 5', 'BBH', 'IFEval', 'CO‚ÇÇ cost (kg)', 'Flagged', 'MoE', '#Params (B)', 'Hub ‚ù§Ô∏è']\" \n",
    "    assert type(confident) == float, \"confident should be a float\"\n",
    "    assert 0 <= confident <= 1, \"confident should be between 0 and 1\"\n",
    "    assert isinstance(range_matrices, dict), \"range_matrices should be a dict\"\n",
    "    assert type(rank_reversed) == bool, \"rank_reversed should be a bool\"\n",
    " \n",
    "    assert type(str_criteria) == list, \"str_criteria should be a list\"\n",
    "    for c in str_criteria:\n",
    "        assert type(c) == tuple, \"Entry of the str_criteria should be a tuple\"\n",
    "        assert c[0] in df.columns, f\"criteria {c[0]} is not allowed. Note that it can only take one of the following values: {df.columns}\"\n",
    "        assert c[1] in df[c[0]].unique(), f\"criteria {c[1]} is not allowed for {c[0]}. Note that it can only take one of the following values: {df[c[0]].unique()}\"\n",
    "\n",
    "    for matric, range in range_matrices.items():\n",
    "        assert matric in matrices, f\"matric {matric} is not allowed. Note that it can only take one of the following values: {matrices}\"\n",
    "        assert isinstance(range, tuple), \"Entry of the range_matrices should be a tuple\"\n",
    "        assert len(range) == 2, \"Entry of the range_matrices should be a tuple of length 2\"\n",
    "        assert (isinstance(range[0], float) or isinstance(range[0], int)) and (isinstance(range[1], float) or isinstance(range[1], int)), \"Entry of the range_matrices should be a tuple of number\"\n",
    "        assert range[0] < range[1], \"Entry of the range_matrices should be a tuple of floats where the first element is smaller than the second element\"\n",
    "    MAX_SCORE = 100\n",
    "    \n",
    "\n",
    "    this_df = df.copy()\n",
    "    this_df[\"new_score\"] = 0    \n",
    "\n",
    "    #add more condition\n",
    "    if len(num_criteria) == 0: \n",
    "        this_df[\"new_score\"] = df[\"Average ‚¨ÜÔ∏è\"]\n",
    "    #add a new column new_score that get the average of the selected criteria in df \n",
    "    else:\n",
    "        \n",
    "        for c in num_criteria:\n",
    "            this_df[\"new_score\"] += this_df[c]\n",
    "        \n",
    "        for s_tuple in str_criteria:\n",
    "        #     if s_tuple[1] == this_df[s_tuple[0]]:\n",
    "        #         this_df[\"str_score\"] += MAX_SCORE\n",
    "            this_df.loc[this_df[s_tuple[0]] == s_tuple[1], \"new_score\"] += MAX_SCORE\n",
    "        this_df[\"new_score\"] = this_df[\"new_score\"] / (len(num_criteria) + len(str_criteria))\n",
    "        this_df[\"new_score\"] = this_df[\"new_score\"] * confident + df[\"Average ‚¨ÜÔ∏è\"] * (1 - confident)\n",
    "    \n",
    "    for matric, range in range_matrices.items():\n",
    "        this_df.loc[this_df[matric] < range[0], \"new_score\"] = 0\n",
    "        this_df.loc[this_df[matric] > range[1], \"new_score\"] = 0\n",
    "\n",
    "\n",
    "    if rank_reversed:\n",
    "        this_df = this_df.sort_values(by=[\"new_score\"], ascending=True)\n",
    "    else:\n",
    "        this_df = this_df.sort_values(by=[\"new_score\"], ascending=False)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return this_df[\"eval_name\"][:num_top_model]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking of tech Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040    MaziyarPanahi_calme-3.2-instruct-78b_bfloat16\n",
      "1036    MaziyarPanahi_calme-3.1-instruct-78b_bfloat16\n",
      "2219          dfurman_CalmeRys-78B-Orpo-v0.1_bfloat16\n",
      "Name: eval_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#tech industry\n",
    "tech_cri = [\"#Params (B)\", \"MUSR\"]\n",
    "tech_industry_models = [(\"Architecture\", \"GPTNeoXForCausalLM\"), (\"Architecture\", \"LlamaForCausalLM\"), (\"Architecture\", \"Qwen2ForCausalLM\"), (\"Architecture\", \"Qwen2MoeForCausalLM\"), (\"Architecture\",\"T5ForConditionalGeneration\"), (\"Architecture\", \"CohereForCausalLM\"), (\"Architecture\", \"GPTJForCausalLM\")]\n",
    "print(get_rank(tech_cri, confident=0.5, num_top_model=3, str_criteria = tech_industry_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20% confident - tech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040        MaziyarPanahi_calme-3.2-instruct-78b_bfloat16\n",
      "1036        MaziyarPanahi_calme-3.1-instruct-78b_bfloat16\n",
      "2219              dfurman_CalmeRys-78B-Orpo-v0.1_bfloat16\n",
      "1030             MaziyarPanahi_calme-2.4-rys-78b_bfloat16\n",
      "2519    huihui-ai_Qwen2.5-72B-Instruct-abliterated_bfl...\n",
      "Name: eval_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(get_rank(tech_cri, confident=0.2, num_top_model=5, str_criteria = tech_industry_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Academic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040    MaziyarPanahi_calme-3.2-instruct-78b_bfloat16\n",
      "2219          dfurman_CalmeRys-78B-Orpo-v0.1_bfloat16\n",
      "1036    MaziyarPanahi_calme-3.1-instruct-78b_bfloat16\n",
      "Name: eval_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "academic_num_cri = [\"MUSR\", \"MATH Lvl 5\", \"GPQA\"]\n",
    "print(get_rank(academic_num_cri, confident=0.5, num_top_model=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20% confident academic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040        MaziyarPanahi_calme-3.2-instruct-78b_bfloat16\n",
      "2219              dfurman_CalmeRys-78B-Orpo-v0.1_bfloat16\n",
      "1036        MaziyarPanahi_calme-3.1-instruct-78b_bfloat16\n",
      "1030             MaziyarPanahi_calme-2.4-rys-78b_bfloat16\n",
      "2519    huihui-ai_Qwen2.5-72B-Instruct-abliterated_bfl...\n",
      "Name: eval_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(get_rank(academic_num_cri, confident=0.2, num_top_model=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking of legal industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040    MaziyarPanahi_calme-3.2-instruct-78b_bfloat16\n",
      "1036    MaziyarPanahi_calme-3.1-instruct-78b_bfloat16\n",
      "2219          dfurman_CalmeRys-78B-Orpo-v0.1_bfloat16\n",
      "1030         MaziyarPanahi_calme-2.4-rys-78b_bfloat16\n",
      "1314               Qwen_Qwen2.5-72B-Instruct_bfloat16\n",
      "Name: eval_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Legal industry\n",
    "legal_cri = [\"MMLU-PRO\", \"BBH\"]\n",
    "print(get_rank(legal_cri, confident=0.1, num_top_model=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20% confident legal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040    MaziyarPanahi_calme-3.2-instruct-78b_bfloat16\n",
      "1036    MaziyarPanahi_calme-3.1-instruct-78b_bfloat16\n",
      "1030         MaziyarPanahi_calme-2.4-rys-78b_bfloat16\n",
      "2219          dfurman_CalmeRys-78B-Orpo-v0.1_bfloat16\n",
      "3267         newsbang_Homer-v1.0-Qwen2.5-72B_bfloat16\n",
      "Name: eval_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(get_rank(legal_cri, confident=0.9, num_top_model=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manufacture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2282       ehristoforu_falcon3-ultraset_float16\n",
      "3875    unsloth_phi-4-unsloth-bnb-4bit_bfloat16\n",
      "3874            unsloth_phi-4-bnb-4bit_bfloat16\n",
      "Name: eval_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "manufac_num_cri = [\"MMLU-PRO\", \"#Params (B)\", \"BBH\", \"IFEval\"]\n",
    "best_architecture_for_manufacturing = [(\"Architecture\", \"LlamaForCausalLM\"), (\"Architecture\", \"GPTJForCausalLM\"), (\"Architecture\", \"CohereForCausalLM\"), \n",
    "                                       (\"Architecture\", \"T5ForConditionalGeneration\"), (\"Architecture\", \"RwkvForCausalLM\")]\n",
    "find_tune = [(\"Type\", \"üî∂ fine-tuned on domain-specific datasets\")]\n",
    "manu_str_cri = best_architecture_for_manufacturing + find_tune\n",
    "\n",
    "print(get_rank(manufac_num_cri, confident=0.5, num_top_model=3, str_criteria=manu_str_cri, range_matrices = {\"CO‚ÇÇ cost (kg)\": (0, 8), \"#Params (B)\": (0, 10)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20% confident manufacture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040    MaziyarPanahi_calme-3.2-instruct-78b_bfloat16\n",
      "1036    MaziyarPanahi_calme-3.1-instruct-78b_bfloat16\n",
      "2219          dfurman_CalmeRys-78B-Orpo-v0.1_bfloat16\n",
      "Name: eval_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(get_rank(manufac_num_cri, confident=0.1, num_top_model=3, str_criteria=manu_str_cri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1036    MaziyarPanahi_calme-3.1-instruct-78b_bfloat16\n",
      "2219          dfurman_CalmeRys-78B-Orpo-v0.1_bfloat16\n",
      "1030         MaziyarPanahi_calme-2.4-rys-78b_bfloat16\n",
      "1013     MaziyarPanahi_calme-2.1-qwen2.5-72b_bfloat16\n",
      "1314               Qwen_Qwen2.5-72B-Instruct_bfloat16\n",
      "1020     MaziyarPanahi_calme-2.2-qwen2.5-72b_bfloat16\n",
      "3049       meta-llama_Llama-3.3-70B-Instruct_bfloat16\n",
      "1310               Qwen_Qwen2.5-32B-Instruct_bfloat16\n",
      "2343           fluently-lm_FluentlyLM-Prinum_bfloat16\n",
      "3099    mistralai_Mistral-Large-Instruct-2411_float16\n",
      "Name: eval_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cs_num_cri = [\"IFEval\", \"MMLU-PRO\"]\n",
    "cs_str_cri = [(\"T\", \"üí¨\"), (\"Type\", \"üí¨ chat models (RLHF, DPO, IFT, ...)\")]\n",
    "\n",
    "print(get_rank(cs_num_cri, confident=0.8, num_top_model=10, str_criteria=cs_str_cri))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customer service - 20% confident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1036    MaziyarPanahi_calme-3.1-instruct-78b_bfloat16\n",
      "2219          dfurman_CalmeRys-78B-Orpo-v0.1_bfloat16\n",
      "1030         MaziyarPanahi_calme-2.4-rys-78b_bfloat16\n",
      "1314               Qwen_Qwen2.5-72B-Instruct_bfloat16\n",
      "1013     MaziyarPanahi_calme-2.1-qwen2.5-72b_bfloat16\n",
      "1020     MaziyarPanahi_calme-2.2-qwen2.5-72b_bfloat16\n",
      "2343           fluently-lm_FluentlyLM-Prinum_bfloat16\n",
      "2296         ehristoforu_qwen2.5-test-32b-it_bfloat16\n",
      "1310               Qwen_Qwen2.5-32B-Instruct_bfloat16\n",
      "3099    mistralai_Mistral-Large-Instruct-2411_float16\n",
      "Name: eval_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(get_rank(cs_num_cri, confident=0.2, num_top_model=10, str_criteria=cs_str_cri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank by Co2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking for co2 with range(10, 10000)\n",
      "0              0-hero_Matter-0.2-7B-DPO_bfloat16\n",
      "2674    jaspionjader_Kosmos-EVAA-v12-8B_bfloat16\n",
      "2675     jaspionjader_Kosmos-EVAA-v2-8B_bfloat16\n",
      "Name: eval_name, dtype: object\n",
      "normal co2 rank\n",
      "2436                           gpt2_float16\n",
      "2191     cpayne1303_llama-43m-beta_bfloat16\n",
      "2190    cpayne1303_cp2024-instruct_bfloat16\n",
      "Name: eval_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "co2_cri = [\"CO‚ÇÇ cost (kg)\"]\n",
    "print(\"ranking for co2 with range(10, 10000)\")\n",
    "print(get_rank(co2_cri, confident=1.0, rank_reversed=True, num_top_model=3,range_matrices = {\"CO‚ÇÇ cost (kg)\": (10, 10000)}))\n",
    "\n",
    "print(\"normal co2 rank\")\n",
    "print(get_rank(co2_cri, confident=1.0, num_top_model=3, rank_reversed=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse151a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
